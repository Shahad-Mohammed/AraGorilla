"1. instruction: إدخل جملة باللغة العربية واستخدم خدمة استخراج الميزات المقدمة بواسطة ConvBERT للحصول على معلومات حول الجملة.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n2. instruction: قم بإنشاء برنامج يستخدم ConvBERT لتحليل نصوص باللغة العربية واستخراج المعلومات الرئيسية منها.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n3. instruction: تدرب نموذج تعلم آلي باستخدام ConvBERT لتصنيف النصوص في اللغة العربية.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n4. instruction: استخدم ConvBERT لتحليل وتفسير نصوص أدبية باللغة العربية.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n5. instruction: تجميع بيانات نصية باللغة العربية واستخدام ConvBERT لاستخراج سمات هامة من النصوص.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n6. instruction: تحليل الإشارات النصية باستخدام ConvBERT لفهم معنى العبارات العربية.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n7. instruction: تحليل نصوص التعليم الإلكتروني باستخدام ConvBERT لفهم محتوى المقالات التعليمية باللغة العربية.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n8. instruction: استخدم ConvBERT لفحص المنشورات على وسائل التواصل الاجتماعي باللغة العربية لفهم مشاعر ومحتوى النصوص.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n9. instruction: قم بتنفيذ دراسة لغوية باستخدام ConvBERT لتحليل بنية الجمل والعبارات باللغة العربية.\n   api: domain: Natural Language Processing Feature Extraction\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction\n        api_name: YituTech/conv-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n10. instruction: استخدم ConvBERT لتحليل النصوص الطبية باللغة العربية لاستخراج المعلومات الطبية الهامة.\n    api: domain: Natural Language Processing Feature Extraction\n         framework: Hugging Face Transformers\n         functionality: Feature Extraction\n         api_name: YituTech/conv-bert-base\n         api_call: AutoModel.from_pretrained('YituTech/conv-bert-base')\n         api_arguments: N/A\n         python_environment_requirements: transformers\n         example_code: N/A\n         performance: dataset: N/A\n         accuracy: N/A\n         description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."
"1. instruction: نحن نرغب في تطوير تطبيق لمقارنة أحجام الأشياء المختلفة. هل يمكنك اقتراح API لاستخراج الميزات والبقاء على رأس المشكلة؟ api: domain: Computer Vision Object Detection framework: TensorFlow functionality: Feature Extraction api_name: ssd_mobilenet_v2_coco api_call: object_detection_feature_extraction() api_arguments: image_path, object_classes python_environment_requirements: TensorFlow, OpenCV example_code: result = object_detection_feature_extraction('image.jpg', ['car', 'person']) performance: dataset: COCO dataset accuracy: 0.67 description: An API for feature extraction using SSD MobileNet V2 on the COCO dataset.\n2. instruction: نريد تطوير تطبيق لتحليل الموسيقى وتحديد الألحان الموجودة في ملفات الصوت. هل يمكنك اقتراح API ملائم لهذا الغرض؟ api: domain: Audio Processing Music Analysis framework: Librosa functionality: Feature Extraction api_name: chroma_stft api_call: librosa.feature.chroma_stft() api_arguments: audio_path, sample_rate python_environment_requirements: Librosa, NumPy example_code: features = librosa.feature.chroma_stft(y, sr) performance: dataset: Custom music dataset accuracy: N/A description: An API for extracting chroma feature using Short-Time Fourier Transform for music analysis.\n3. instruction: بناء نظام لتصنيف الأسماء إلى فئات مختلفة باستخدام تقنيات تعلم الآلة. ما هي API الموصى بها لاستخراج الميزات اللازمة؟ api: domain: Machine Learning Name Classification framework: Scikit-learn functionality: Feature Extraction api_name: CountVectorizer api_call: CountVectorizer() api_arguments: text_data python_environment_requirements: Scikit-learn, Pandas example_code: vectorizer = CountVectorizer() X = vectorizer.fit_transform(text_data) performance: dataset: Name classification dataset accuracy: N/A description: An API for converting text data into a matrix of token counts.\n4. instruction: نريد إنشاء أداة توليد تلقائي لمحتوى الفيديوهات باستخدام تقنيات معالجة اللغة الطبيعية. هل يمكنك اقتراح API مناسبة للاستخدام؟ api: domain: Natural Language Processing Video Content Generation framework: OpenAI GPT-3 functionality: Text Generation api_name: openai-gpt3 api_call: generate_text() api_arguments: text_data python_environment_requirements: OpenAI GPT-3 example_code: generated_text = generate_text(text_data) performance: dataset: N/A accuracy: N/A description: An API for generating text using OpenAI's GPT-3 language model.\n5. instruction: نرغب في تطوير تطبيق للتعرف على الوجوه في الصور. هل يمكنك اقتراح API لاستخراج خصائص الوجوه؟ api: domain: Computer Vision Face Recognition framework: OpenCV functionality: Feature Extraction api_name: face_recognition api_call: extract_face_features() api_arguments: image_path python_environment_requirements: OpenCV, Dlib example_code: features = extract_face_features('image.jpg') performance: dataset: Labeled faces in the wild accuracy: 0.89 description: An API for extracting facial features using Dlib for face recognition.\n6. instruction: نود تطوير نظام لتحليل المشاهد في مقاطع الفيديو للكشف عن أنماط معينة. ما هي الAPI الأمثل لاستخراج الميزات اللازمة لهذا الهدف؟ api: domain: Computer Vision Video Scene Analysis framework: OpenCV functionality: Feature Extraction api_name: hog api_call: cv2.HOGDescriptor() api_arguments: video_path python_environment_requirements: OpenCV example_code: hog = cv2.HOGDescriptor() features = hog.compute(frame) performance: dataset: Custom video dataset accuracy: N/A description: An API for extracting Histogram of Oriented Gradients features for video scene analysis.\n7. instruction: نحتاج إلى تحويل النص إلى صوت باللغة العربية لتكامله في تطبيقنا. هل يمكنك اقتراح API مناسبة لهذا الغرض؟ api: domain: Text-to-Speech Arabic Speech Synthesis framework: Google Text-to-Speech functionality: Synthesize Speech api_name: google-text-to-speech api_call: synthesize_speech() api_arguments: text_data python_environment_requirements: Google Cloud SDK example_code: audio_data = synthesize_speech(text_data, language='ar') performance: dataset: N/A accuracy: N/A description: An API for generating speech from text in Arabic using Google's Text-to-Speech service.\n8. instruction: نرغب في تطوير أداة لتحليل العواطف في النصوص الإنجليزية. هل يمكنك اقتراح API لاستخراج الميزات اللازمة لذلك؟ api: domain: Natural Language Processing Sentiment Analysis framework: VADER SentimentIntensityAnalyzer functionality: Feature Extraction api_name: vader_sentiment api_call: SentimentIntensityAnalyzer() api_arguments: text_data python_environment_requirements: NLTK example_code: analyzer = SentimentIntensityAnalyzer() sentiment_scores = analyzer.polarity_scores(text_data) performance: dataset: English sentiment text dataset accuracy: N/A description: An API for extracting sentiment features using VADER sentiment analyzer for English text.\n9. instruction: نريد تحسين يدوية تشكيل النصوص العربية. هل يمكنك اقتراح API يمكن استخدامه لهذا الغرض؟ api: domain: Natural Language Processing Arabic Text Processing framework: Farasa functionality: Text Normalization api_name: farasa_text_processing api_call: normalize_text() api_arguments: arabic_text python_environment_requirements: Farasa-NLP example_code: processed_text = normalize_text(arabic_text) performance: dataset: N/A accuracy: N/A description: An API for normalizing Arabic text using the Farasa-NLP toolkit.\n10. instruction: لدينا تطبيق يتعامل مع بيانات زمنية تتطلب استخلاص سلسلة زمنية. هل يمكنك اقتراح API توفر هذه الوظيفة؟ api: domain: Time Series Analysis Time Series Extraction framework: Pandas functionality: Feature Extraction api_name: pandas_time_series api_call: pd.TimeSeries() api_arguments: time_data python_environment_requirements: Pandas, NumPy example_code: time_series_data = pd.TimeSeries(time_data) performance: dataset: N/A accuracy: N/A description: An API for handling time series data extraction using Pandas library."
"1. instruction: يجب على الباحثين تحليل مجموعة من التغريدات لفهم سلوك المستهلكين تجاه منتج معين. يمكن استخدام واجهة برمجة التطبيقات التالية لاستخراج الميزات اللازمة: api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n\n2. instruction: تريد الشركة التحليلية استخدام نموذج محدد لتقدير المشاعر المختلفة المعبر عنها في سلسلة من المقالات الصحفية. يمكن استخدام واجهة برمجة التطبيقات التالية لأداء هذه المهمة: api: domain: Natural Language Processing Sentiment Analysis framework: Hugging Face Transformers functionality: Sentiment Analysis api_name: some-sentiment-analysis-model api_call: AutoModel.from_pretrained('some-sentiment-analysis-model') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained sentiment analysis model for analyzing sentiments in textual data.\n\n3. instruction: يطلب منك تحليل الصور الطبية لتحديد نوع معين من الأورام. يمكنك استخدام الأداة التالية لتوليد الميزات اللازمة من الصور: api: domain: Computer Vision Image Analysis framework: TensorFlow functionality: Feature Extraction api_name: some-image-analysis-tool api_call: model = some_image_analysis_tool() api_arguments: N/A python_environment_requirements: TensorFlow example_code: N/A performance: dataset: N/A accuracy: N/A description: A tool for extracting features from medical images to analyze and detect specific types of tumors.\n\n4. instruction: أريدك أن تساعدني في فحص النصوص القانونية للكشف عن أي معلومات حساسة. يمكن استخدام الواجهة البرمجية التالية لمساعدتك في هذه المهمة: api: domain: Natural Language Processing Information Extraction framework: spaCy functionality: Named Entity Recognition api_name: some-legal-ner-model api_call: nlp = some_legal_ner_model() api_arguments: N/A python_environment_requirements: spaCy example_code: N/A performance: dataset: N/A accuracy: N/A description: A Named Entity Recognition model specialized in extracting sensitive information from legal texts.\n\n5. instruction: لديك مجموعة كبيرة من البيانات النصية وترغب في تصنيفها إلى فئات مختلفة. يمكنك استخدام واجهة برمجة التطبيقات التالية لتحقيق ذلك: api: domain: Natural Language Processing Text Classification framework: Hugging Face Transformers functionality: Text Classification api_name: some-text-classification-model api_call: AutoModel.from_pretrained('some-text-classification-model') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained model for classifying textual data into different categories.\n\n6. instruction: تريد تحليل المشاهد في مقاطع الفيديو لاكتشاف أشكال معينة. يمكنك استخدام الأداة التالية لاستخراج الخصائص الفريدة من المشاهد: api: domain: Computer Vision Video Analysis framework: OpenCV functionality: Feature Extraction api_name: some-video-analysis-tool api_call: video_tool = some_video_analysis_tool() api_arguments: N/A python_environment_requirements: OpenCV example_code: N/A performance: dataset: N/A accuracy: N/A description: A tool for extracting unique features from video scenes to detect specific shapes.\n\n7. instruction: تحتاج إلى تحديد المواضع التي تظهر فيها وجوه الأشخاص على عدة صور فوتوغرافية. يمكنك استخدام الواجهة البرمجية التالية لتحقيق هذا الهدف: api: domain: Computer Vision Facial Recognition framework: OpenCV functionality: Facial Detection api_name: some-facial-recognition-tool api_call: face_detector = some_facial_recognition_tool() api_arguments: N/A python_environment_requirements: OpenCV example_code: N/A performance: dataset: N/A accuracy: N/A description: A tool for detecting and locating faces within multiple photographic images.\n\n8. instruction: ترغب في تقدير سن الأفراد من صورهم الشخصية. يمكنك استخدام الأداة التالية لاستخراج السن المقدرة من الصور: api: domain: Computer Vision Age Estimation framework: TensorFlow functionality: Age Estimation api_name: some-age-estimation-tool api_call: age_estimator = some_age_estimation_tool() api_arguments: N/A python_environment_requirements: TensorFlow example_code: N/A performance: dataset: N/A accuracy: N/A description: A tool for estimating the age of individuals from their personal images.\n\n9. instruction: أود تحويل سلسلة من التدوينات الصوتية إلى نصوص مكتوبة. يمكنك استخدام واجهة برمجة التطبيقات التالية لتنفيذ هذه المهمة: api: domain: Natural Language Processing Speech to Text Conversion framework: Google Cloud Speech-To-Text functionality: Speech-to-Text Conversion api_name: google-speech-to-text api_call: google_asr = google_speech_to_text() api_arguments: N/A python_environment_requirements: Google Cloud SDK example_code: N/A performance: dataset: N/A accuracy: N/A description: Google Cloud's Speech-to-Text API for converting spoken audio into written text.\n\n10. instruction: أريدك أن تساعدني في تحليل الرسائل الإلكترونية لفهم محتواها وتصنيفها وصنع تقييم لها. يمكنك استخدام الواجهة البرمجية التالية لأداء تحليل النصوص بدقة: api: domain: Natural Language Processing Text Analysis framework: spaCy functionality: Text Analysis api_name: some-text-analysis-tool api_call: text_analyzer = some_text_analysis_tool() api_arguments: N/A python_environment_requirements: spaCy example_code: N/A performance: dataset: N/A accuracy: N/A description: A text analysis tool utilizing spaCy for accurately analyzing and categorizing email messages."
"1. instruction: استخدم النموذج المدرب مسبقًا \"distilbert-base-arabic\" لتحليل محتوى النصوص العربية.\n   api: domain: Natural Language Processing Text Analysis\n   framework: Hugging Face Transformers\n   functionality: Text Analysis\n   api_name: distilbert-base-arabic\n   api_call: AutoModel.from_pretrained('aubmindlab/bert-base-arabert')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained DistilBERT model for text analysis in Arabic provided by AUB Mind Lab, based on the Hugging Face Transformers library.\n\n2. instruction: قم باستخدام النموذج \"Tashkeela/bert-base-arabic\" لتحويل النصوص العربية إلى نصوص مشكلة.\n   api: domain: Natural Language Processing Text Processing\n   framework: Hugging Face Transformers\n   functionality: Text Processing\n   api_name: Tashkeela/bert-base-arabic\n   api_call: AutoModel.from_pretrained('Tashkeela/bert-base-arabic')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained BERT model for adding diacritics to Arabic text provided by Tashkeela, based on the Hugging Face Transformers library.\n\n3. instruction: استخدم النموذج \"UBC-NLP/ARBERT\" لتصنيف التعليقات العربية إلى إيجابية وسلبية.\n   api: domain: Natural Language Processing Sentiment Analysis\n   framework: Hugging Face Transformers\n   functionality: Sentiment Analysis\n   api_name: UBC-NLP/ARBERT\n   api_call: AutoModel.from_pretrained('UBC-NLP/ARBERT')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained ARBERT model for sentiment analysis in Arabic comments provided by UBC-NLP, based on the Hugging Face Transformers library.\n\n4. instruction: استخدم نموذج \"CAMeL-Lab/bert-base-camel-sentiment-arabic\" لتحليل المشاعر في النصوص العربية.\n   api: domain: Natural Language Processing Sentiment Analysis\n   framework: Hugging Face Transformers\n   functionality: Sentiment Analysis\n   api_name: CAMeL-Lab/bert-base-camel-sentiment-arabic\n   api_call: AutoModel.from_pretrained('CAMeL-Lab/bert-base-camel-sentiment-arabic')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained BERT model for sentiment analysis in Arabic text provided by CAMeL Lab, based on the Hugging Face Transformers library.\n\n5. instruction: استخدم النموذج \"aubmindlab/Arabic-and-MSA-distilBERT-sentiment\" لتحليل مشاعر النصوص العربية والإنجليزية.\n   api: domain: Natural Language Processing Sentiment Analysis\n   framework: Hugging Face Transformers\n   functionality: Sentiment Analysis\n   api_name: aubmindlab/Arabic-and-MSA-distilBERT-sentiment\n   api_call: AutoModel.from_pretrained('aubmindlab/Arabic-and-MSA-distilBERT-sentiment')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained DistilBERT model for sentiment analysis in Arabic and English text provided by AUB Mind Lab, based on the Hugging Face Transformers library.\n\n6. instruction: قم باستخدام النموذج \"araevec/araelectra-base\" لتوقع المواقف أو الرؤى في النصوص العربية.\n   api: domain: Natural Language Processing Text Analysis\n   framework: Hugging Face Transformers\n   functionality: Text Analysis\n   api_name: araevec/araelectra-base\n   api_call: AutoModel.from_pretrained('araevec/araelectra-base')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained AraELECTRA model for stance or viewpoint prediction in Arabic text provided by AraEvec, based on the Hugging Face Transformers library.\n\n7. instruction: استخدم النموذج \"UBC-NLP/Arabic-CodeBERT\" لتحليل وتصنيف النصوص البرمجية باللغة العربية.\n   api: domain: Natural Language Processing Code Analysis\n   framework: Hugging Face Transformers\n   functionality: Code Analysis\n   api_name: UBC-NLP/Arabic-CodeBERT\n   api_call: AutoModel.from_pretrained('UBC-NLP/Arabic-CodeBERT')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained Arabic CodeBERT model for source code analysis and classification in Arabic provided by UBC-NLP, based on the Hugging Face Transformers library.\n\n8. instruction: إستخدم النموذج \"UBC-NLP/Arabic-CodeBERT\" لتحليل وتصنيف النصوص البرمجية باللغة العربية.\n   api: domain: Natural Language Processing Code Analysis\n   framework: Hugging Face Transformers\n   functionality: Code Analysis\n   api_name: UBC-NLP/Arabic-CodeBERT\n   api_call: AutoModel.from_pretrained('UBC-NLP/Arabic-CodeBERT')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained Arabic CodeBERT model for source code analysis and classification in Arabic provided by UBC-NLP, based on the Hugging Face Transformers library.\n\n9. instruction: قم بتحسين إنتاجية الكتابة باللغة العربية باستخدام النموذج \"asafaya/bert-base-arabic-qa\".\n   api: domain: Natural Language Processing Language Generation\n   framework: Hugging Face Transformers\n   functionality: Language Generation\n   api_name: asafaya/bert-base-arabic-qa\n   api_call: AutoModel.from_pretrained('asafaya/bert-base-arabic-qa')\n   api_arguments: N/A\n   python_environment_requirements: transformers\n   example_code: N/A\n   performance: dataset: N/A\n   accuracy: N/A\n   description: A pre-trained BERT model for Arabic language question answering provided by Asafaya, based on the Hugging Face Transformers library.\n\n10. instruction: قم بتعلم التعرف على الكلمات الرئيسية في النصوص العربية باستخدام النموذج \"asafaya/Arabic-BERT-MWE\".\n    api: domain: Natural Language Processing Keyword Extraction\n    framework: Hugging Face Transformers\n    functionality: Keyword Extraction\n    api_name: asafaya/Arabic-BERT-MWE\n    api_call: AutoModel.from_pretrained('asafaya/Arabic-BERT-MWE')\n    api_arguments: N/A\n    python_environment_requirements: transformers\n    example_code: N/A\n    performance: dataset: N/A\n    accuracy: N/A\n    description: A pre-trained Arabic BERT model for multi-word expression identification in Arabic text provided by Asafaya, based on the Hugging Face Transformers library."
"1. instruction: اكتب قصيدة قصيرة تبدأ بجملة \"في ليلة من الليالي القمرية الهادئة\".api: domain: Natural Language Processing Sentiment Analysis framework: Hugging Face Transformers functionality: Sentiment Analysis api_name: facebook/bart-large-cnn api_call: AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-cnn') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: BART Large CNN model by Facebook for sentiment analysis using Hugging Face Transformers.\n\n2. instruction: قم بإنشاء تقرير موجز يلخص نتائج البحث العلمي الحديث في مجال الذكاء الاصطناعي.api: domain: Natural Language Processing Text Summarization framework: Hugging Face Transformers functionality: Text Summarization api_name: t5-base api_call: T5ForConditionalGeneration.from_pretrained('t5-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: T5 base model for text summarization provided by Hugging Face Transformers.\n\n3. instruction: أنشئ موقع ويب يقوم بتحليل النصوص العربية واستخراج المعلومات الرئيسية منها.api: domain: Natural Language Processing Named Entity Recognition framework: Hugging Face Transformers functionality: Named Entity Recognition api_name: dbmdz/bert-large-cased-finetuned-conll03-arabic api_call: pipeline('ner', model='dbmdz/bert-large-cased-finetuned-conll03-arabic') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: Pre-trained BERT model fine-tuned for Named Entity Recognition on Arabic text.\n\n4. instruction: تحدث عن مشروعك البحثي الحالي ونتائج الدراسات التحليلية التي قمت بها.api: domain: Natural Language Processing Text Generation framework: Hugging Face Transformers functionality: Text Generation api_name: gpt2 api_call: GPT2LMHeadModel.from_pretrained('gpt2') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: GPT-2 model for text generation provided by the Hugging Face Transformers library.\n\n5. instruction: تصميم نموذج تعلم آلي لتحليل الصور والتعرف على الأشياء فيها.api: domain: Computer Vision Object Detection framework: PyTorch functionality: Object Detection api_name: torchvision.models.detection.fasterrcnn_resnet50_fpn api_call: torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) api_arguments: N/A python_environment_requirements: torchvision, torch example_code: N/A performance: dataset: N/A accuracy: N/A description: Faster R-CNN model with ResNet-50 backbone for object detection in images provided by PyTorch.\n\n6. instruction: كتابة مقالة علمية تشرح مفهوم الشبكات العصبية الاصطناعية وتطبيقاتها في حل المشكلات الحديثة.api: domain: Machine Learning Neural Networks framework: TensorFlow functionality: Neural Networks api_name: tensorflow.keras.Sequential api_call: tensorflow.keras.Sequential() api_arguments: N/A python_environment_requirements: tensorflow example_code: N/A performance: dataset: N/A accuracy: N/A description: TensorFlow's Keras Sequential model for building neural networks.\n\n7. instruction: تطوير تطبيق تفاعلي يقوم بتشخيص أمراض العيون باستخدام تقنيات التعلم الآلي.api: domain: Healthcare Medical Diagnosis framework: Scikit-Learn functionality: Medical Diagnosis api_name: sklearn.svm.SVC api_call: sklearn.svm.SVC() api_arguments: N/A python_environment_requirements: scikit-learn example_code: N/A performance: dataset: N/A accuracy: N/A description: Support Vector Machine classifier for diagnosing eye diseases using Scikit-Learn.\n\n8. instruction: إنشاء نموذج لتحليل المشاعر في التغريدات المتداولة عبر وسائل التواصل الاجتماعي.api: domain: Natural Language Processing Sentiment Analysis framework: PyTorch functionality: Sentiment Analysis api_name: sentiment-transformer api_call: SentimentTransformerModel() api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: Custom sentiment analysis model utilizing Transformers library for PyTorch.\n\n9. instruction: تصميم نظام توصيف ذكي لتوصية الأفلام للمستخدمين بناءً على تفضيلاتهم السابقة.api: domain: Recommender Systems framework: Surprise functionality: Recommender System api_name: SVD api_call: SVD() api_arguments: N/A python_environment_requirements: scikit-surprise example_code: N/A performance: dataset: N/A accuracy: N/A description: Singular Value Decomposition-based recommender system implemented using the Surprise library.\n\n10. instruction: برمجة تطبيق يستخدم تقنيات التعرف على النصوص لتحليل مضمون الرسائل الإلكترونية.api: domain: Natural Language Processing Text Classification framework: Hugging Face Transformers functionality: Text Classification api_name: distilbert-base-uncased api_call: DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: DistilBERT model for text classification provided by Hugging Face Transformers.\n"
"1. instruction: إنشاء نموذج لتحليل المشاعر من تغريدات العملاء باستخدام API Sentiment140.\n   api: domain: Natural Language Processing Sentiment Analysis\n   framework: Hugging Face Transformers\n   functionality: Sentiment Analysis\n   api_name: API Sentiment140\n   api_call: sentiment140_model.analyze_tweets(tweets)\n   api_arguments: tweets (list of strings)\n   python_environment_requirements: transformers, numpy\n   example_code: \n   ```python\n   from sentiment140 import sentiment140_model\n\n   tweets = [\"أحب هذا المنتج كثيرًا!\", \"الخدمة كانت سريعة ورائعة\"]\n   results = sentiment140_model.analyze_tweets(tweets)\n   print(results)\n   ```\n   performance: \n   dataset: Various customer tweet datasets\n   accuracy: 85% on average\n   description: API Sentiment140 provides pre-trained models for sentiment analysis on customer tweets, based on the Hugging Face Transformers library.\n\n2. instruction: تطوير أداة لاستخراج المفاهيم الرئيسية من المقالات العلمية باستخدام API ScispaCy.\n   api: domain: Natural Language Processing Information Extraction\n   framework: ScispaCy\n   functionality: Concept Extraction\n   api_name: API ScispaCy\n   api_call: scispacy_model.extract_concepts(articles)\n   api_arguments: articles (list of strings)\n   python_environment_requirements: scispacy, pandas\n   example_code:\n   ```python\n   from scispacy import scispacy_model\n   import pandas as pd\n\n   articles = [\"تم اكتشاف العديد من الكواكب الجديدة في كوكبة الثعلب.\", \"المقال يتحدث عن أحدث الابحاث التي أجريت في مجال علوم الحاسوب.\"]\n   results = scispacy_model.extract_concepts(articles)\n   df = pd.DataFrame(results)\n   print(df)\n   ```\n   performance: \n   dataset: Scientific articles dataset\n   accuracy: 90% on average\n   description: API ScispaCy offers capabilities to extract key concepts from scientific articles using the ScispaCy framework.\n\n3. instruction: إنشاء نموذج لتحليل الجوانب الايجابية والسلبية في استطلاعات رأي العملاء باستخدام API VADER.\n   api: domain: Natural Language Processing Sentiment Analysis\n   framework: NLTK\n   functionality: Opinion Mining\n   api_name: API VADER\n   api_call: vader_model.analyze_surveys(surveys)\n   api_arguments: surveys (list of strings)\n   python_environment_requirements: nltk, pandas\n   example_code:\n   ```python\n   from nltk.sentiment import vader_model\n   import pandas as pd\n\n   surveys = [\"الخدمة جيدة ولكن يمكن تحسين الوقت.\", \"منتج عالي الجودة وسهل الاستخدام.\"]\n   results = vader_model.analyze_surveys(surveys)\n   df = pd.DataFrame(results)\n   print(df)\n   ```\n   performance: \n   dataset: Customer survey data\n   accuracy: 88% on average\n   description: API VADER enables the analysis of positive and negative aspects in customer surveys using the NLTK framework.\n\n4. instruction: تنفيذ تقييم لغوي للتقارير الطبية باستخدام API Med7.\n   api: domain: Natural Language Processing Medical Text Analysis\n   framework: spaCy\n   functionality: Medical Named Entity Recognition\n   api_name: API Med7\n   api_call: med7_model.analyze_reports(reports)\n   api_arguments: reports (list of strings)\n   python_environment_requirements: spacy, numpy\n   example_code:\n   ```python\n   from med7 import med7_model\n   import numpy as np\n\n   reports = [\"المريض يعاني من ألم في الصدر وضيق في التنفس.\", \"تم تشخيص الحالة على أنها التهاب فيروسي.\"]\n   results = med7_model.analyze_reports(reports)\n   print(np.asarray(results))\n   ```\n   performance: \n   dataset: Medical reports dataset\n   accuracy: 92% on average\n   description: API Med7 provides linguistic evaluation for medical reports through Medical Named Entity Recognition using the spaCy framework.\n\n5. instruction: إعداد نموذج لاستخراج المعلومات الرئيسية من الروايات باستخدام API BERT.\n   api: domain: Natural Language Processing Information Extraction\n   framework: Hugging Face Transformers\n   functionality: Information Retrieval\n   api_name: API BERT\n   api_call: bert_model.extract_information(novels)\n   api_arguments: novels (list of strings)\n   python_environment_requirements: transformers, pandas\n   example_code:\n   ```python\n   from huggingface.transformers import bert_model\n   import pandas as pd\n\n   novels = [\"رواية 'عصفور السطح' تروي حكاية فتاة يتيمة في العاصمة.\", \"كتاب 'الأفعى' يدور حول الغموض والجريمة.\"]\n   results = bert_model.extract_information(novels)\n   df = pd.DataFrame(results)\n   print(df)\n   ```\n   performance: \n   dataset: Collection of novels\n   accuracy: 87% on average\n   description: API BERT facilitates the extraction of key information from novels utilizing the Hugging Face Transformers framework.\n\n6. instruction: إنشاء تطبيق لتلخيص المقالات الإخبارية باستخدام API Sumy.\n   api: domain: Natural Language Processing Text Summarization\n   framework: Sumy\n   functionality: Text Summarization\n   api_name: API Sumy\n   api_call: sumy_model.summarize_articles(articles)\n   api_arguments: articles (list of strings)\n   python_environment_requirements: sumy, seaborn\n   example_code:\n   ```python\n   from sumy.summarizer import sumy_model\n   import seaborn as sns\n\n   articles = [\"تم الإعلان عن افتتاح مطعم جديد في وسط المدينة.\", \"الحكومة تطلق مبادرة جديدة لدعم الشباب في مجال التكنولوجيا.\"]\n   summary = sumy_model.summarize_articles(articles)\n   sns.barplot(x=[len(article) for article in articles], y=['Article 1', 'Article 2'])\n   ```\n   performance: \n   dataset: News articles dataset\n   accuracy: 85% on average\n   description: API Sumy enables the creation of a news summarization application using the Sumy framework for text summarization.\n\n7. instruction: تجهيز نموذج للكشف عن التزييف في المراجعات الإلكترونية باستخدام API FakeReviewDetector.\n   api: domain: Natural Language Processing Fake Review Detection\n   framework: TensorFlow\n   functionality: Review Analysis\n   api_name: API FakeReviewDetector\n   api_call: fake_review_model.detect_fake_reviews(reviews)\n   api_arguments: reviews (list of strings)\n   python_environment_requirements: tensorflow, pandas\n   example_code:\n   ```python\n   from fake_review_detector import fake_review_model\n   import pandas as pd\n\n   reviews = [\"هذا المنتج رائع جدًا ويستحق كل ريال أنفقته.\", \"الخدمة كانت سيئة والمنتج لم يكن كما وعدوا.\"]\n   results = fake_review_model.detect_fake_reviews(reviews)\n   df = pd.DataFrame(results)\n   print(df)\n   ```\n   performance: \n   dataset: Synthetic review dataset\n   accuracy: 89% on average\n   description: API FakeReviewDetector facilitates the preparation of a model for detecting fake reviews using the TensorFlow framework for review analysis.\n\n8. instruction: تنفيذ تحليل لغوي لسجلات الدردشة العبرية باستخدام API HebrewNLP.\n   api: domain: Natural Language Processing Chat Analysis\n   framework: OpenNLP\n   functionality: Language Detection\n   api_name: API HebrewNLP\n   api_call: hebrew_nlp_model.analyze_chat_records(records)\n   api_arguments: records (list of strings)\n   python_environment_requirements: opennlp, matplotlib\n   example_code:\n   ```python\n   from hebrew_nlp import hebrew_nlp_model\n   import matplotlib.pyplot as plt\n\n   records = [\"שלום, איך אפשר לעזור לך?\", \"מה השעה עכשיו בגריניץ'?\", \"תודה רבה על העזרה!\"]\n   results = hebrew_nlp_model.analyze_chat_records(records)\n   plt.pie([len(record) for record in records], labels=records)\n   ```\n   performance: \n   dataset: Hebrew chat records dataset\n   accuracy: 86% on average\n   description: API HebrewNLP allows the execution of linguistic analysis on Hebrew chat records using the OpenNLP framework for language detection.\n\n9. instruction: تنفيذ تقييم لسياق الحوار في المحادثات الصوتية باستخدام API ContextVoice.\n   api: domain: Natural Language Processing Speech Recognition\n   framework: DeepSpeech\n   functionality: Conversation Context Analysis\n   api_name: API ContextVoice\n   api_call: context_voice_model.analyze_voice_conversations(conversations)\n   api_arguments: conversations (list of strings)\n   python_environment_requirements: deepspeech, nltk\n   example_code:\n   ```python\n   from context_voice import context_voice_model\n   from nltk.tokenize import sent_tokenize\n\n   conversations = [\"What's the weather like today?\", \"Play some jazz music please.\"]\n   results = context_voice_model.analyze_voice_conversations(conversations)\n   sentences = sent_tokenize(' '.join(conversations))\n   print(\"Number of sentences:\", len(sentences))\n   ```\n   performance: \n   dataset: Voice conversations dataset\n   accuracy: 83% on average\n   description: API ContextVoice implements an evaluation of conversation context in voice interactions using the DeepSpeech framework for speech recognition.\n\n10. instruction: إعداد نموذج لتحديد موقع الجملة الصحيح في اللغة العربية باستخدام API MADAMIRA.\n    api: domain: Natural Language Processing Arabic Language Processing\n    framework: MADAMIRA\n    functionality: Arabic Sentence Parsing\n    api_name: API MADAMIRA\n    api_call: madamira_model.parse_sentences(sentences)\n    api_arguments: sentences (list of strings)\n    python_environment_requirements: madamira, numpy\n    example_code:\n    ```python\n    from madamira import madamira_model\n    import numpy as np\n\n    sentences = [\"ذهبت إلى السوق بعد العمل.\", \"الأصدقاء يزورون بيتهم يوم الجمعة.\"]\n    results = madamira_model.parse_sentences(sentences)\n    print(np.asarray(results))\n    ```\n    performance: \n    dataset: Arabic sentences dataset\n    accuracy: 91% on average\n    description: API MADAMIRA prepares a model for determining correct sentence structure in Arabic utilizing the MADAMIRA framework for Arabic language processing.\n"
"1. instruction: نريد تطوير نظام يمكنه فهم اللغة العربية وتوقع الردود على أسئلة محددة. هل يمكنكم تزويدنا بأداة تستخدم تقنيات استخراج الميزات من النصوص؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n2. instruction: أريد إنشاء نموذج تعلم آلي يمكنه تحديد مواقف السيارات في صور فضائية، هل يمكن استخدام API لاستخراج الميزات للمساعدة في هذا المشروع؟api: domain: Computer Vision Feature Extraction framework: TensorFlow functionality: Feature Extraction api_name: TensorFlow/ImageNet api_call: tf.keras.applications.InceptionV3(weights='imagenet', include_top=False) api_arguments: N/A python_environment_requirements: TensorFlow example_code: N/A performance: dataset: ImageNet accuracy: 77.9% description: Pre-trained InceptionV3 model from ImageNet for feature extraction in computer vision tasks, provided by TensorFlow.\n3. instruction: نحن بحاجة إلى بناء نظام قادر على تحليل المشاهد المدرسية واستخراج ميزات من الفيديوهات، هل يمكن توفير API يساعد في هذه المهمة؟api: domain: Video Analysis Feature Extraction framework: OpenCV functionality: Feature Extraction api_name: OpenCV/FeatureExtraction api_call: cv2.VideoCapture('video.mp4') api_arguments: N/A python_environment_requirements: OpenCV example_code: N/A performance: dataset: N/A accuracy: N/A description: OpenCV library for video analysis and feature extraction from video files.\n4. instruction: أرغب في إنشاء نظام قادر على استخلاص سمات رئيسية من أدبيات الشعر لإجراء تحليل عميق، هل يمكنك توجيهي إلى API مناسب لهذا الغرض؟api: domain: Natural Language Processing Feature Extraction framework: SpaCy functionality: Feature Extraction api_name: SpaCy/LinguisticFeatures api_call: nlp = spacy.load('en_core_web_sm') api_arguments: N/A python_environment_requirements: SpaCy example_code: N/A performance: dataset: N/A accuracy: N/A description: SpaCy library for linguistic feature extraction and text analysis tasks.\n5. instruction: لدى شركتنا متجر إلكتروني ونريد تحليل البريد الإلكتروني الخاص بالعملاء لفهم اهتماماتهم واستخراج معلومات هامة، هل يمكن استخدام API لهذا الغرض؟api: domain: Natural Language Processing Feature Extraction framework: TextBlob functionality: Feature Extraction api_name: TextBlob/EmailAnalysis api_call: TextBlob(email_text) api_arguments: email_text (str) - Text content of the email python_environment_requirements: TextBlob example_code: N/A performance: dataset: N/A accuracy: N/A description: TextBlob library for email text analysis and feature extraction.\n6. instruction: نود تطوير تطبيق يمكنه تحليل مشاهد الفيديو المباشرة وتحديد الأشخاص والأجسام المهمة في الإطار، هل يمكن توجيهنا إلى API مناسب لاستخراج الميزات من الفيديو؟api: domain: Video Analysis Feature Extraction framework: YOLO (You Only Look Once) functionality: Object Detection api_name: YOLO/ObjectDetection api_call: yolov3.detect_objects(video_frame) api_arguments: video_frame (array) - Frame of the video as an input python_environment_requirements: YOLO example_code: N/A performance: dataset: COCO accuracy: 33.3% description: YOLO (You Only Look Once) model for real-time object detection in video frames, with pre-trained weights on COCO dataset.\n7. instruction: نرغب في تطوير نظام قادر على تحليل لغة الإشارة من مقاطع الفيديو وتحديد الإيماءات الهامة، هل يمكن استخدام API لاستخراج الميزات اللازمة؟api: domain: Video Analysis Feature Extraction framework: MediaPipe functionality: Feature Extraction api_name: MediaPipe/SignLanguage api_call: mediapipe.LanguageSignRecognition(video_clip) api_arguments: video_clip (array) - Array of video frames for sign language analysis python_environment_requirements: MediaPipe example_code: N/A performance: dataset: N/A accuracy: N/A description: MediaPipe library for sign language recognition and feature extraction from video clips.\n8. instruction: أود إنشاء نظام لفهم مواقف السيارات في الوقت الفعلي من تيار الفيديو المباشر، هل يوجد API يمكنني استخدامه لهذه المهمة؟api: domain: Computer Vision Feature Extraction framework: OpenCV functionality: Feature Extraction api_name: OpenCV/VehicleDetection api_call: cv2.VideoCapture('video_stream') api_arguments: N/A python_environment_requirements: OpenCV example_code: N/A performance: dataset: N/A accuracy: N/A description: OpenCV library for real-time vehicle detection and feature extraction from live video streams.\n9. instruction: نحن بحاجة إلى بعض التوجيه في تستخدام API لاستخراج ميزات الوجه والتعرف على المشاهير في الصور، هل يوجد API مناسب لهذه المهمة؟api: domain: Computer Vision Feature Extraction framework: Microsoft Azure Computer Vision functionality: Face Recognition api_name: MicrosoftAzure/FaceAPI api_call: face_client.face_recognition(image_file) api_arguments: image_file (file) - Image file containing the face to recognize python_environment_requirements: Microsoft Azure example_code: N/A performance: dataset: N/A accuracy: N/A description: Microsoft Azure FaceAPI for face recognition and celebrity identification in images."
"1. instruction: نريد تطوير تطبيق يتيح للمستخدمين تحويل النص إلى كلام بناءً على واجهة برمجة التطبيقات. \n   api: domain: Natural Language Processing Text-to-Speech\n        framework: Hugging Face Transformers\n        functionality: Text-to-Speech Conversion\n        api_name: YituTech/t2s-transformer-arabic\n        api_call: AutoModel.from_pretrained('YituTech/t2s-transformer-arabic')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained model specifically tailored for Arabic text-to-speech conversion by YituTech, utilizing the Hugging Face Transformers library.\n\n2. instruction: لدينا حاجة لتصميم نظام لتحليل مشاعر التعليقات على وسائل التواصل الاجتماعي. كمطور، ما هي أفضل طريقة للاستفادة من خوارزميات استخراج الميزات؟\n   api: domain: Natural Language Processing Sentiment Analysis\n        framework: Hugging Face Transformers\n        functionality: Feature Extraction for Sentiment Analysis\n        api_name: YituTech/sentiment-bert-base\n        api_call: AutoModel.from_pretrained('YituTech/sentiment-bert-base')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained BERT model optimized for sentiment analysis feature extraction, provided by YituTech through the Hugging Face Transformers library.\n\n3. instruction: نحتاج إلى تطوير أداة تساعد في تفسير معاني النصوص القانونية. هل يوجد واجهة برمجة تقدم هذه الإمكانية؟\n   api: domain: Legal Text Analysis\n        framework: Hugging Face Transformers\n        functionality: Legal Text Interpretation\n        api_name: YituTech/legal-bert\n        api_call: AutoModel.from_pretrained('YituTech/legal-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A specialized pre-trained BERT model for legal text analysis provided by YituTech leveraging the Hugging Face Transformers framework.\n\n4. instruction: عميلنا يبحث عن أداة تقوم بتحقيق ترجمة نصوص طبية إلى عدة لغات. هل يمكننا الاعتماد على واجهة برمجة لهذا الغرض؟\n   api: domain: Natural Language Processing Medical Text Translation\n        framework: Hugging Face Transformers\n        functionality: Medical Text Translation\n        api_name: YituTech/medtrans-bert\n        api_call: AutoModel.from_pretrained('YituTech/medtrans-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A specialized pre-trained BERT model tailored for medical text translation, designed by YituTech using the Hugging Face Transformers library.\n\n5. instruction: نواجه تحدي في تحليل نصوص تقنية معقدة لتعزيز فهمها للجمهور العام. هل يمكنك اقتراح واجهة برمجية لاستخراج المعلومات الأساسية؟\n   api: domain: Natural Language Processing Technical Text Analysis\n        framework: Hugging Face Transformers\n        functionality: Basic Information Extraction for Technical Texts\n        api_name: YituTech/techinfo-bert\n        api_call: AutoModel.from_pretrained('YituTech/techinfo-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained BERT model optimized for extracting key information from complex technical texts, developed by YituTech with the Hugging Face Transformers library.\n\n6. instruction: نرغب في تطوير نموذج لتحليل النصوص الشعرية وتحديد سماتها الأساسية. هل يمكن استخدام واجهة برمجة معينة لهذا الغرض؟\n   api: domain: Natural Language Processing Poetry Analysis\n        framework: Hugging Face Transformers\n        functionality: Poetic Text Feature Extraction\n        api_name: YituTech/poetry-bert\n        api_call: AutoModel.from_pretrained('YituTech/poetry-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A specialized pre-trained BERT model tailored for analyzing poetic texts and extracting their key features, provided by YituTech through the Hugging Face Transformers library.\n\n7. instruction: ترغب شركتنا في تنفيذ نظام لاكتشاف التلاعب بالبيانات الصوتية. هل تستطيع توجيهنا إلى واجهة برمجية لهذه الغرض؟\n   api: domain: Audio Data Manipulation Detection\n        framework: Hugging Face Transformers\n        functionality: Audio Data Tampering Detection\n        api_name: YituTech/audio-tamper-bert\n        api_call: AutoModel.from_pretrained('YituTech/audio-tamper-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A specialized pre-trained BERT model designed for detecting manipulation in audio data, offered by YituTech in collaboration with the Hugging Face Transformers library.\n\n8. instruction: نحتاج إلى إنشاء نموذج لتعريف الأسماء الخاصة في نصوص اللغة العربية. هل يمكن مساعدتنا في العثور على واجهة برمجية تفي بالغرض؟\n   api: domain: Named Entity Recognition Arabic Text\n        framework: Hugging Face Transformers\n        functionality: Named Entity Recognition for Arabic Text\n        api_name: YituTech/ner-arabic-bert\n        api_call: AutoModel.from_pretrained('YituTech/ner-arabic-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A specialized pre-trained BERT model optimized for identifying named entities in Arabic language texts, developed by YituTech using the Hugging Face Transformers library.\n\n9. instruction: تخطط منظمتنا لتطوير أداة لتحليل النمط اللغوي في النصوص الإعلانية. هل توفر أي واجهة برمجية تحقق هذه الوظيفة؟\n   api: domain: Natural Language Processing Linguistic Pattern Analysis\n        framework: Hugging Face Transformers\n        functionality: Linguistic Pattern Analysis for Advertisements\n        api_name: YituTech/adv-pattern-bert\n        api_call: AutoModel.from_pretrained('YituTech/adv-pattern-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained BERT model specialized for analyzing linguistic patterns in advertising texts, developed by YituTech with the assistance of the Hugging Face Transformers library.\n\n10. instruction: عميلنا يبحث عن تطبيق لتوسيع قاعدة المعرفة ذاتية الاستخدام. هل تعتقد يمكن استخدام واجهة برمجية لتحديد مفاهيم المحتوى بشكل أكثر دقة؟\n    api: domain: Natural Language Processing Content Concept Extraction\n        framework: Hugging Face Transformers\n        functionality: Content Concept Extraction for Knowledge Base\n        api_name: YituTech/kb-concept-bert\n        api_call: AutoModel.from_pretrained('YituTech/kb-concept-bert')\n        api_arguments: N/A\n        python_environment_requirements: transformers\n        example_code: N/A\n        performance: dataset: N/A\n        accuracy: N/A\n        description: A pre-trained BERT model customized for accurately extracting content concepts for expanding self-service knowledge bases, created by YituTech in collaboration with the Hugging Face Transformers library."
"1. instruction: اكتب نص قصير يتحدث عن تأثير التكنولوجيا في حياة الأفراد. api: domain: Natural Language Processing Sentiment Analysis framework: Hugging Face Transformers functionality: Sentiment Analysis api_name: YituTech/bert-base-uncased-sentiment api_call: BertForSequenceClassification.from_pretrained('YituTech/bert-base-uncased-sentiment') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained BERT model for sentiment analysis provided by YituTech, based on the Hugging Face Transformers library.\n\n2. instruction: قم بكتابة موضوع تعليمي حول كيفية بناء نموذج توقع الطقس باستخدام الذكاء الاصطناعي. api: domain: Machine Learning Weather Forecasting framework: TensorFlow functionality: Model Training api_name: tensorflow/weather-forecast-api api_call: make_weather_forecast_model() api_arguments: location, date python_environment_requirements: tensorflow, numpy example_code: N/A performance: dataset: Weather data accuracy: N/A description: An API for building weather forecasting models using artificial intelligence with TensorFlow.\n\n3. instruction: كتابة سيناريو قصير يدور حول لغز جريمة قتل لتمرين مهارات التحليل النصي. api: domain: Natural Language Processing Text Analysis framework: Hugging Face Transformers functionality: Text Analysis api_name: YituTech/distilbert-base-uncased api_call: DistilBertModel.from_pretrained('YituTech/distilbert-base-uncased') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained DistilBERT model for text analysis provided by YituTech, based on the Hugging Face Transformers library.\n\n4. instruction: إنشاء نص قصير حول فوائد الرياضة اليومية على الصحة العقلية. api: domain: Natural Language Processing Content Generation framework: GPT-3 functionality: Text Generation api_name: openai/gpt-3 api_call: OpenAI().create_text(text_prompt) api_arguments: text_prompt python_environment_requirements: openai example_code: N/A performance: dataset: N/A accuracy: N/A description: A powerful language model for text generation provided by OpenAI's GPT-3.\n\n5. instruction: كتابة قصة قصيرة تعبر عن قيم الصداقة والتعاون بين الأفراد في المجتمع. api: domain: Natural Language Processing Text Generation framework: GPT-3 functionality: Text Generation api_name: openai/gpt-3 api_call: OpenAI().generate_text(text_prompt) api_arguments: text_prompt python_environment_requirements: openai example_code: N/A performance: dataset: N/A accuracy: N/A description: A state-of-the-art language model for text generation provided by OpenAI's GPT-3.\n\n6. instruction: كتابة نص تسويقي جذاب حول منتج جديد في مجال التكنولوجيا الحديثة. api: domain: Natural Language Processing Content Creation framework: Hugging Face Transformers functionality: Content Creation api_name: facebook/bart-large-cnn api_call: BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained BART model for content creation provided by Facebook AI, based on the Hugging Face Transformers library.\n\n7. instruction: أنشىء قصة قصيرة تستعرض أهمية الحفاظ على البيئة والحفاظ على التنوع البيولوجي. api: domain: Natural Language Processing Text Generation framework: GPT-3 functionality: Text Generation api_name: openai/gpt-3 api_call: generate_biodiversity_story() api_arguments: N/A python_environment_requirements: openai example_code: N/A performance: dataset: N/A accuracy: N/A description: A cutting-edge language model for generating content related to biodiversity conservation, provided by OpenAI's GPT-3.\n\n8. instruction: كتابة موضوع تعليمي حول أساسيات البرمجة باستخدام لغة Python للمبتدئين. api: domain: Programming Beginners Python framework: Python functionality: Programming Tutorial api_name: python/python-tutorial api_call: start_python_tutorial() api_arguments: N/A python_environment_requirements: python example_code: N/A performance: dataset: N/A accuracy: N/A description: An API for providing beginner-friendly tutorials on programming with Python.\n\n9. instruction: إنشاء قصة خيالية تتحدث عن رحلة استكشافية إلى كوكب غير معروف في رحلة عبر الزمن. api: domain: Natural Language Processing Text Generation framework: GPT-3 functionality: Text Generation api_name: openai/gpt-3 api_call: generate_time_travel_exploration_story() api_arguments: N/A python_environment_requirements: openai example_code: N/A performance: dataset: N/A accuracy: N/A description: A state-of-the-art language model for generating fictional stories related to time travel exploration, provided by OpenAI's GPT-3.\n\n10. instruction: كتابة نص دعائي مبتكر لحملة توعية بمشكلة تغير المناخ وأثرها على البيئة. api: domain: Natural Language Processing Content Creation framework: Hugging Face Transformers functionality: Content Creation api_name: facebook/bart-large-cnn api_call: BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained BART model for creating innovative advertising content provided by Facebook AI, based on the Hugging Face Transformers library."
"1. instruction: استخدام تحليل نصوص تقنية لمعالجة بيانات كبيرة المحفوظة في قاعدة بيانات. هل بإمكانك توضيح كيفية استخدام واجهة البرمجة لاستخراج المعلومات؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n2. instruction: تسليط الضوء على إمكانية استخدام تحليل نصوص تقنية لمساعدة الباحثين في تحليل الأبحاث العلمية. هل يمكنك اقتراح طريقة تفصيلية للواجهة البرمجية؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n3. instruction: تحليل تعليقات المستخدمين على منصة التجارة الإلكترونية باستخدام تقنيات استخراج الميزات. كيف يمكننا تكامل واجهة البرمجة في هذا السياق؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n4. instruction: ابتكار نظام تقييم آلي لتحليل جودة المقالات الصحفية. هل يوجد اقتراح لتكامل تحليل نصوص تقنية؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n5. instruction: تحليل التعليقات السلبية على وسائل التواصل الاجتماعي لتقديم تقرير شهري للشركات الصغيرة. هل يُمكن توجيهنا للاستفادة من واجهة البرمجة في هذا السياق؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n6. instruction: تطبيق تحليل نصوص تقنية لفهم مدى تأثير إعلانات الشركات على سلوك المستهلكين. هل يمكن إعطاء مثال على كيفية استخدام واجهة البرمجة بشكل فعال؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n7. instruction: تحليل أسلوب الكتابة في المقالات الأدبية باستخدام تقنيات استخراج الميزات. هل بإمكانك مقترح حول كيفية تكامل واجهة البرمجة في هذا السياق؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n8. instruction: استخدام تحليل نصوص تقنية لتحديد الاتجاهات السياسية من خلال دراسة الخطاب السياسي. هل يوجد استعراض لكيفية استخدام واجهة البرمجة في هذه الحالة؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n9. instruction: تطوير أداة تحليل نصوص تقنية لمساعدة الطلاب في تحليل تحليل نصوصهم الأدبية. ما هي الخطوات الأساسية للتكامل مع واجهة البرمجة المُقدمة؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library.\n   \n10. instruction: تحليل الردود على الاستبيانات الاستهلاكية باستخدام الاسترجاع التلقائي للمعلومات. ما هي الإرشادات الأساسية لتوظيف واجهة البرمجة في هذا السياق؟api: domain: Natural Language Processing Feature Extraction framework: Hugging Face Transformers functionality: Feature Extraction api_name: YituTech/conv-bert-base api_call: AutoModel.from_pretrained('YituTech/conv-bert-base') api_arguments: N/A python_environment_requirements: transformers example_code: N/A performance: dataset: N/A accuracy: N/A description: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."
