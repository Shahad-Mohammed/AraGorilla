"1. instruction: لدينا مشروع لتصميم نظام تشخيص ذكاء اصطناعي للأمراض الجلدية، نريد استخدام تقنيات تحليل الصور لتحديد نوع الإصابة. \n   api: \n   domain: Image Processing \n   framework: OpenCV \n   functionality: Image Analysis \n   api_name: cv2.Canny \n   api_call: cv2.Canny(image, threshold1, threshold2) \n   api_arguments: image (input image), threshold1 (first threshold for the hysteresis procedure), threshold2 (second threshold for the hysteresis procedure) \n   python_environment_requirements: OpenCV \n   example_code: \n   ```\n   import cv2\n   edges = cv2.Canny(image, threshold1, threshold2)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: OpenCV's Canny edge detection algorithm for image analysis.\n   \n2. instruction: نريد تطوير نظام تأشير ذكي للمركبات على الطرق السريعة، يقوم بتحديد المسارات الآمنة وتقديم تحذيرات في الوقت الحقيقي.\n   api: \n   domain: Computer Vision \n   framework: TensorFlow \n   functionality: Object Detection \n   api_name: TensorFlow Object Detection API \n   api_call: tf.image.detect_images(images) \n   api_arguments: images (input images to detect objects) \n   python_environment_requirements: TensorFlow \n   example_code: \n   ```\n   import tensorflow as tf\n   detections = tf.image.detect_images(images)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: TensorFlow's Object Detection API for developing intelligent vehicle signage systems.\n\n3. instruction: ترغب شركتنا في تطوير نظام لتحليل البيانات الكبيرة وتوليد تقارير تحليلية معقدة عن سلوك المستخدمين على منصتنا الإلكترونية.\n   api: \n   domain: Data Analytics \n   framework: Apache Spark \n   functionality: Data Processing \n   api_name: DataFrame \n   api_call: spark_session.read.load(data_path) \n   api_arguments: data_path (path to the data source) \n   python_environment_requirements: Apache Spark \n   example_code: \n   ```\n   from pyspark.sql import SparkSession\n   spark_session = SparkSession.builder.appName(\"DataAnalysis\").getOrCreate()\n   dataframe = spark_session.read.load(data_path)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: Apache Spark's DataFrame API for analyzing big data and generating complex analytical reports on user behavior on our electronic platform.\n\n4. instruction: أرغب في تطوير نظام توصيف تلقائي للصور الطبية لتحديد الأمراض والتشخيصات بدقة عالية.\n   api: \n   domain: Medical Imaging \n   framework: TensorFlow \n   functionality: Image Classification \n   api_name: EfficientNet \n   api_call: efficientnet_model.predict(image) \n   api_arguments: image (input medical image) \n   python_environment_requirements: TensorFlow \n   example_code: \n   ```\n   from efficientnet_model import EfficientNet\n   prediction = efficientnet_model.predict(image)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: EfficientNet model for automatic description of medical images to accurately identify diseases and diagnoses.\n\n5. instruction: نحن بحاجة إلى تطوير نظام التعرف على الكلام بالعربية لتحسين تجربة المستخدم على منصتنا الرقمية.\n   api: \n   domain: Speech Recognition \n   framework: Google Cloud Speech-to-Text API \n   functionality: Speech-to-Text Conversion \n   api_name: Google Cloud Speech-to-Text API \n   api_call: google_speech_to_text.transcribe(audio_file) \n   api_arguments: audio_file (input audio file) \n   python_environment_requirements: Google Cloud SDK \n   example_code: \n   ```\n   from google.cloud import speech_v1p1beta1 as speech\n   client = speech.SpeechClient()\n   response = client.recognize(config=config, audio=audio)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: Google Cloud's Speech-to-Text API for developing Arabic speech recognition system to enhance user experience on our digital platform.\n\n6. instruction: نريد استخدام تقنيات التعلم الآلي لتحليل أنماط الشراء لزيادة فعالية استراتيجيات التسويق.\n   api: \n   domain: Machine Learning \n   framework: Scikit-learn \n   functionality: Clustering \n   api_name: KMeans \n   api_call: KMeans(n_clusters=num_clusters) \n   api_arguments: num_clusters (number of clusters for analysis) \n   python_environment_requirements: Scikit-learn \n   example_code: \n   ```\n   from sklearn.cluster import KMeans\n   kmeans = KMeans(n_clusters=num_clusters)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: Scikit-learn's KMeans clustering algorithm for utilizing machine learning techniques in analyzing purchasing patterns to enhance marketing strategies.\n\n7. instruction: تحتاج شركتنا إلى توظيف نموذج تعلم آلي لتحديد الأخبار المزيفة على منصتنا الإخبارية الرقمية.\n   api: \n   domain: Text Analysis \n   framework: TensorFlow \n   functionality: Text Classification \n   api_name: LSTM \n   api_call: lstm_model.predict(text) \n   api_arguments: text (input news article) \n   python_environment_requirements: TensorFlow \n   example_code: \n   ```\n   from lstm_model import LSTM\n   prediction = lstm_model.predict(text)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: LSTM model for employing machine learning to detect fake news on our digital news platform.\n\n8. instruction: نريد تصميم نظام توصيف تلقائي للصور الفضائية لتحليل مناطق الزراعة وتحديد السلالات النباتية الموجودة.\n   api: \n   domain: Remote Sensing \n   framework: PyTorch \n   functionality: Image Segmentation \n   api_name: Mask R-CNN \n   api_call: mask_rcnn_model.segment(image) \n   api_arguments: image (input satellite image) \n   python_environment_requirements: PyTorch \n   example_code: \n   ```\n   from mask_rcnn_model import MaskRCNN\n   segmentation_result = mask_rcnn_model.segment(image)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: PyTorch's Mask R-CNN model for automatic description of satellite images to analyze agricultural regions and identify plant species.\n\n9. instruction: لدينا مشروع لتصميم نظام تشخيص ذكاء اصطناعي لأمراض القلب، نحتاج إلى تطبيق تقنيات التعلم العميق لتحليل النتائج الطبية.\n   api: \n   domain: Medical Imaging \n   framework: Keras \n   functionality: Deep Learning \n   api_name: CNN \n   api_call: cnn_model.evaluate(data) \n   api_arguments: data (input medical data for evaluation) \n   python_environment_requirements: Keras \n   example_code: \n   ```\n   from cnn_model import CNN\n   evaluation_result = cnn_model.evaluate(data)\n   ``` \n   performance: \n   dataset: N/A \n   accuracy: N/A \n   description: Keras' CNN model for developing artificial intelligence diagnosis system for heart diseases, utilizing deep learning techniques for medical result analysis.\n\n10. instruction: تقوم شركتنا بتصميم نظام تعرف على الكتابة اليدوية، نريد تحويل النص المكتوب يدويًا إلى نص رقمي لتطبيقاتنا.\n    api: \n    domain: Handwriting Recognition \n    framework: PyTorch \n    functionality: Text Recognition \n    api_name: CRNN \n    api_call: crnn_model.recognize(image) \n    api_arguments: image (input handwritten image) \n    python_environment_requirements: PyTorch \n    example_code: \n    ```\n    from crnn_model import CRNN\n    text_result = crnn_model.recognize(image)\n    ``` \n    performance: \n    dataset: N/A \n    accuracy: N/A \n    description: PyTorch's CRNN model for designing a handwritten text recognition system, converting manually written text to digital text for our applications."
"1. instruction: نحن نطور تطبيقًا لتوصيات الأفلام ونحتاج إلى استخلاص الميزات من وصف الفيلم. استخدم API dmis-lab/biobert-v1.1 لاستخراج الميزات المطلوبة.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pre-trained biomedical language representation model for extracting features from biomedical text.\n\n2. instruction: تقوم شركتنا بتطوير نظام لتحليل المشاهد الفيلمية وتحتاج إلى تقدير مشاعر الشخصيات في المشهد. استخدم API dmis-lab/biobert-v1.1 لاستخراج المعلومات اللازمة.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pre-trained biomedical language representation model for extracting features from text data.\n   \n3. instruction: نحن نبني نظاماً للنصوص القصيرة ونحتاج إلى تحليل المفردات الرئيسية في النصوص. يمكنك استخدام API dmis-lab/biobert-v1.1 لاستخراج هذه المفردات.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pre-trained model for extracting key vocabulary from text data.\n\n4. instruction: تطوير أداة لتحليل تغريدات المستخدمين وتحديد المواضيع الرئيسية لها. استخدم API dmis-lab/biobert-v1.1 لاستخراج هذه المواضيع.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pretrained model that can be used to extract key topics from user tweets.\n\n5. instruction: لدينا مشروع لتحليل المقالات الطبية ونريد تحديد المفاهيم الرئيسية في النصوص. اعتمد على API dmis-lab/biobert-v1.1 لهذا التحليل.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pretrained model that can identify key concepts in medical articles.\n\n6. instruction: نريد استخدام تقنية التعلم الآلي لتصنيف الصور من حيوانات البحر. جرب استخدام API dmis-lab/biobert-v1.1 لهذا الغرض.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a tool that can be utilized for classifying images of marine animals using machine learning techniques.\n\n7. instruction: تنفذ شركتنا مشروعًا لتتبع تطور الأفلام ونريد تحليل الردود على الإعلانات السينمائية. استخدم API dmis-lab/biobert-v1.1 لهذا التحليل.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a model that can be employed to analyze responses to movie advertisements for a film tracking project.\n\n8. instruction: نحن بصدد بناء نظام لتقديم توصيات لكتب المستخدمين. نحتاج إلى استخراج مواضيع رئيسية من الكتب. اعتمد على API dmis-lab/biobert-v1.1 لهذا الغرض.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a pre-trained model that can help extract key topics from user books to provide recommendations.\n\n9. instruction: تعمل شركتنا على تطبيق للتعرف على الأشجار وتريد استخدام تقنيات التعلم الآلي لهذا الغرض. استخدم API dmis-lab/biobert-v1.1 لاستخراج المعلومات اللازمة.\n   api: domain: Natural Language Processing Feature Extraction\n   framework: Hugging Face Transformers\n   functionality: Feature Extraction\n   api_name: dmis-lab/biobert-v1.1\n   api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n   api_arguments: []\n   python_environment_requirements: ['transformers']\n   example_code:\n   \n   performance:\n   dataset:\n   accuracy:\n   description: BioBERT is a tool that can be utilized for tree recognition applications using machine learning techniques.\n\n10. instruction: نحن في عملية تطوير تطبيق للتنبؤ بأداء الأفلام في شباك التذاكر ونحتاج إلى تحليل أراء المستخدمين. اعتمد على API dmis-lab/biobert-v1.1 لاستخراج هذه الأراء.\n    api: domain: Natural Language Processing Feature Extraction\n    framework: Hugging Face Transformers\n    functionality: Feature Extraction\n    api_name: dmis-lab/biobert-v1.1\n    api_call: AutoModel.from_pretrained('dmis-lab/biobert-v1.1')\n    api_arguments: []\n    python_environment_requirements: ['transformers']\n    example_code:\n    \n    performance:\n    dataset:\n    accuracy:\n    description: BioBERT is a pre-trained model that can be used to analyze user opinions for predicting movie performance at the box office."
"3. instruction: قم بتطوير تطبيق يقدم خدمة ترجمة النصوص من اللغة الإنجليزية إلى العربية باستخدام API خدمات ترجمة معروفة.\n   api: domain: Natural Language Processing Translation\n   api_name: google-translate-api\n   api_call: translate(text='Hello', source_language='en', target_language='ar')\n   api_arguments: text, source_language, target_language\n   python_environment_requirements: ['googletrans==4.0.0-rc1']\n   example_code: translate(text='Hello', source_language='en', target_language='ar')\n   performance: dataset: None accuracy: None\n   description: Access Google's translation services to efficiently translate text between English and Arabic.\n\n4. instruction: يرغب العميل في تطوير نظام لتحليل المشاعر في النصوص العربية. عليك استخدام API مخصصة لتحليل المشاعر واستخراج المعلومات المناسبة.\n   api: domain: Natural Language Processing Sentiment Analysis\n   api_name: arabic-sentiment-analysis-api\n   api_call: analyze_sentiment(text='أنا سعيد اليوم')\n   api_arguments: text\n   python_environment_requirements: ['arabic-sentiment==1.0.0']\n   example_code: analyze_sentiment(text='أنا سعيد اليوم')\n   performance: dataset: None accuracy: None\n   description: Utilize a specialized API for sentiment analysis on Arabic texts to extract relevant emotional information.\n   \n5. instruction: عميلك يريد تطوير تطبيق تعليمي للأطفال بحيث يتمكنون من تعلم الحروف العربية بشكل مسلي. استخدم API لتحويل النص إلى صوت لتسهيل عملية التعلم.\n   api: domain: Text-to-Speech\n   api_name: arabic-text-to-speech-api\n   api_call: convert_text_to_speech(text='الحرف الأول هو الألف')\n   api_arguments: text\n   python_environment_requirements: ['pyttsx3==2.90']\n   example_code: convert_text_to_speech(text='الحرف الأول هو الألف')\n   performance: dataset: None accuracy: None\n   description: Use a dedicated API for converting Arabic text to speech to enhance the learning experience for children.\n\n6. instruction: ابن برنامجًا يحول النصوص إلى رموز تعبيرية لتحسين تفاعل المستخدمين مع التطبيقات. اعتمد على API لتحويل النصوص إلى رموز تعبيرية معروفة.\n   api: domain: Natural Language Processing Text-to-Emoji\n   api_name: text-to-emoji-api\n   api_call: convert_text_to_emoji(text='I am happy today')\n   api_arguments: text\n   python_environment_requirements: ['emoji==1.2.0']\n   example_code: convert_text_to_emoji(text='I am happy today')\n   performance: dataset: None accuracy: None\n   description: Enhance user interaction by converting texts to well-known emojis using an API dedicated to text-to-emoji conversion.\n\n7. instruction: تمتلك شركة العميل موقع إلكتروني وترغب في تحسين تجربة المستخدمين من خلال إضافة خاصية توليد نصوص إبداعية آليًا. استخدم API لتوليد نصوص إبداعية بسيطة.\n   api: domain: Natural Language Processing Text Generation\n   api_name: creative-text-generation-api\n   api_call: generate_creative_text()\n   api_arguments: None\n   python_environment_requirements: ['textgenrnn==2.0.0']\n   example_code: generate_creative_text()\n   performance: dataset: None accuracy: None\n   description: Improve user experience on the client's website by implementing a feature that automatically generates creative texts using a dedicated API.\n\n8. instruction: يرغب الزبون في تطوير تطبيق لتوليد عبارات حكم وأقوال مشهورة بشكل تلقائي. استخدم API لتوليد أقوال مشهورة بناءً على مواضيع محددة.\n   api: domain: Natural Language Processing Quote Generation\n   api_name: famous-quote-generation-api\n   api_call: generate_famous_quote(topic='inspiration')\n   api_arguments: topic\n   python_environment_requirements: ['quote-generator==1.5.0']\n   example_code: generate_famous_quote('inspiration')\n   performance: dataset: None accuracy: None\n   description: Develop an app for automatically generating famous quotes and wisdom sayings based on specific topics using a dedicated API.\n\n9. instruction: اكتب برنامجًا يقوم بفهم النصوص باللغة العربية واقتراح كلمات مشابهة للمفردات المدخلة. استخدم API لتوصيات النصوص باللغة العربية.\n   api: domain: Natural Language Processing Text Recommendation\n   api_name: arabic-text-recommendation-api\n   api_call: suggest_similar_words(text='وردة')\n   api_arguments: text\n   python_environment_requirements: ['arabic-recommender==0.8.0']\n   example_code: suggest_similar_words('وردة')\n   performance: dataset: None accuracy: None\n   description: Write a program that understands Arabic texts and suggests similar words for the input vocabulary using an API for Arabic text recommendations.\n\n10. instruction: تطلب شركة العميل تطوير أداة لتحليل تواتر ظهور الكلمات في النصوص العربية. يمكنك الاعتماد على API لتحليل تواتر الكلمات باللغة العربية.\n    api: domain: Natural Language Processing Word Frequency Analysis\n    api_name: arabic-word-frequency-api\n    api_call: analyze_word_frequency(text='هذا هو النص العربي للتحليل')\n    api_arguments: text\n    python_environment_requirements: ['arabic-frequency==2.2.4']\n    example_code: analyze_word_frequency('هذا هو النص العربي للتحليل')\n    performance: dataset: None accuracy: None\n    description: Build a tool for analyzing word frequency in Arabic texts by utilizing an API for Arabic word frequency analysis."
"1. instruction: قم بكتابة قصيدة قصيرة تعبر عن جمال الطبيعة في فصل الربيع.\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('spring beauty in nature', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output.\n\n2. instruction: أكتب موضوعاً تعبيرياً يتحدث عن أهمية التعليم في بناء مجتمع متقدم.\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('importance of education in building advanced society', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output.\n\n3. instruction: قم بكتابة قصة خيالية تبدأ بجملة \"في عالم لا يشبه عالمنا،\".\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('in a world unlike ours', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output.\n\n4. instruction: صمم خريطة ذهنية توضح أهم خطوات بناء مشروع ناجح في العمل.\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('steps to build a successful project at work', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output.\n\n5. instruction: كتب لنا مقدمة تعريفية لمفهوم الذكاء الاصطناعي وتطبيقاته الحديثة.\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('introduction to artificial intelligence and its modern applications', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output.\n\n6. instruction: أنشئ قصيدة شعرية تصف الحب والغرام بشكل ملهم.\n   api: \n   - domain: Multimodal Feature Extraction\n   - framework: Hugging Face Transformers\n   - functionality: Feature Extraction\n   - api_name: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n   - api_call: AutoModel.from_pretrained('cambridgeltl/SapBERT-from-PubMedBERT-fulltext')\n   - api_arguments: input_ids, attention_mask\n   - python_environment_requirements: transformers\n   - example_code: inputs = tokenizer('inspiring poem about love and romance', return_tensors='pt'); outputs = model(**inputs); cls_embedding = outputs.last_hidden_state[:, 0, :]\n   - performance: \n     - dataset: UMLS\n     - accuracy: N/A\n   - description: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."
"1. instruction: يرغب فريق التدريب الرياضي في تصميم نظام لتحليل أداء اللاعبين وتوقع أفضل تشكيلة للمباريات القادمة. هل بمكنك اقتراح استخدام API مناسب لهذا الغرض؟api: domain: Machine Learning framework: Scikit-learn functionality: Machine Learning Model Evaluation api_name: sklearn.ensemble.RandomForestClassifier api_call: RandomForestClassifier(n_estimators=100) api_arguments: ['X_train', 'y_train'] python_environment_requirements: ['scikit-learn'] example_code: from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred) performance: dataset: UCI Machine Learning Repository accuracy: 85% description: RandomForestClassifier is a machine learning model that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n            \n2. instruction: ترغب شركة السيارات في تطوير نظام يتنبأ بالطلب على أنواع معينة من السيارات في السوق بناءً على الاتجاهات الحالية. هل بإمكانك توجيههم نحو استخدام API مناسب لتحقيق ذلك؟api: domain: Machine Learning framework: TensorFlow functionality: Time Series Forecasting api_name: tensorflow.keras.models.Sequential api_call: tensorflow.keras.models.Sequential() api_arguments: ['LSTM', 'Dense', 'Compile'] python_environment_requirements: ['tensorflow'] example_code: from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nmodel = Sequential([LSTM(50), Dense(1)])\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(X_train, y_train, epochs=100) performance: dataset: Kaggle accuracy: Not provided description: LSTM (Long Short-Term Memory) is a type of recurrent neural network that is capable of learning long-term dependencies. It is commonly used for time series forecasting tasks.\n\n3. instruction: تريد شركة التجارة الإلكترونية تحسين توقعاتها لسلوك المستخدمين على الموقع. كيف يمكنني استخدام API لتطوير نموذج تنبؤي بناءً على سجلات الزوار؟api: domain: Machine Learning framework: Scikit-learn functionality: Clustering api_name: sklearn.cluster.KMeans api_call: KMeans(n_clusters=3) api_arguments: ['X'] python_environment_requirements: ['scikit-learn'] example_code: from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(X)\nlabels = kmeans.predict(X) performance: dataset: UCI Machine Learning Repository accuracy: Not provided description: KMeans is a popular clustering algorithm that aims to partition n observations into k clusters where each observation belongs to the cluster with the nearest mean.\n\n4. instruction: لدى شركة التأمين الحاجة إلى تحسين عمليات الكشف عن الاحتيال. كيف يمكن استخدام API لتصميم نظام يكتشف الأنماط الاحتيالية في المعاملات؟api: domain: Machine Learning framework: PyCaret functionality: Anomaly Detection api_name: pycaret.anomaly api_call: create_model('knn') api_arguments: ['data'] python_environment_requirements: ['pycaret'] example_code: from pycaret.anomaly import *\nmodel = create_model('knn', data=df) performance: dataset: Kaggle accuracy: Not provided description: PyCaret is an open-source, low-code machine learning library in Python that automates the end-to-end machine learning workflow, including anomaly detection tasks.\n\n5. instruction: يرغب فريق التطوير في تحسين أداء نظام التوصيات الخاص بهم. هل بإمكانك تقديم API لتنفيذ تقييم دقة نماذج التوصيات؟api: domain: Machine Learning framework: Surprise functionality: Recommender System Evaluation api_name: surprise.model_selection import cross_validate api_call: cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) api_arguments: ['algo', 'data'] python_environment_requirements: ['surprise'] example_code: from surprise.model_selection import cross_validate\nresults = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) performance: dataset: MovieLens accuracy: RMSE: 0.85, MAE: 0.67 description: Surprise is a Python scikit building and analyzing recommender systems.\n\n6. instruction: في إطار مشروعنا الجديد، نحتاج إلى تصميم نظام يتنبأ بتحليلات السوق المالية. هل بإمكانك اقتراح استخدام API ملائم لتحقيق هذا الهدف؟api: domain: Machine Learning framework: XGBoost functionality: Stock Market Prediction api_name: xgboost.XGBRegressor api_call: XGBRegressor() api_arguments: ['X_train', 'y_train'] python_environment_requirements: ['xgboost'] example_code: from xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test) performance: dataset: Yahoo Finance accuracy: Not provided description: XGBoost is an efficient and scalable machine learning library that implements gradient boosting algorithms for prediction tasks.\n\n7. instruction: تريد شركة العقارات تحسين عملية التصنيف التلقائي للعقارات الجديدة. كيف يمكن استخدام API لبناء نموذج يصنف العقارات استنادًا إلى ميزاتها؟api: domain: Machine Learning framework: Scikit-learn functionality: Classification api_name: sklearn.ensemble.GradientBoostingClassifier api_call: GradientBoostingClassifier() api_arguments: ['X_train', 'y_train'] python_environment_requirements: ['scikit-learn'] example_code: from sklearn.ensemble import GradientBoostingClassifier\nmodel = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test) performance: dataset: Kaggle accuracy: Not provided description: Gradient Boosting Classifier is a powerful ensemble learning method that builds a strong predictive model by combining the predictions of multiple weak models.\n\n8. instruction: تريد شركة التكنولوجيا تطوير نظام للتعرف على الأشخاص باستخدام تقنيات الذكاء الاصطناعي. هل بإمكانك توجيههم نحو استخدام API مناسب لتنفيذ هذه المهمة؟api: domain: Machine Learning framework: OpenCV functionality: Facial Recognition api_name: cv2.face.LBPHFaceRecognizer_create api_call: cv2.face.LBPHFaceRecognizer_create() api_arguments: ['images', 'labels'] python_environment_requirements: ['opencv-python'] example_code: recognizer = cv2.face.LBPHFaceRecognizer_create()\nrecognizer.train(images, labels)\npredicted_label = recognizer.predict(test_img) performance: dataset: Custom accuracy: Not provided description: OpenCV is a popular computer vision library that provides tools and algorithms for facial recognition tasks.\n\n9. instruction: نود تصميم نظام يعتمد على الذكاء الاصطناعي لتوقع الأحوال الجوية. هل بإمكانك اقتراح API ملائم لتحليل بيانات الطقس وتوقع الظروف الجوية المستقبلية؟api: domain: Machine Learning framework: scikit-learn functionality: Time Series Forecasting api_name: sklearn.linear_model.LinearRegression api_call: LinearRegression() api_arguments: ['X_train', 'y_train'] python_environment_requirements: ['scikit-learn'] example_code: from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test) performance: dataset: NOAA accuracy: Not provided description: Linear Regression is a simple yet powerful machine learning algorithm commonly used for predicting continuous values based on historical data.\n\n10. instruction: أنا بحاجة إلى تصميم نظام يستخدم تقنيات معالجة اللغة الطبيعية لتحديد إيماءات العملاء وفهم مشاعرهم. هل بمكنك توجيهي نحو استخدام API مناسب لهذا الغرض؟api: domain: Natural Language Processing framework: Hugging Face Transformers functionality: Sentiment Analysis api_name: facebook/bart-large api_call: BartModel.from_pretrained('facebook/bart-large') api_arguments: ['inputs'] python_environment_requirements: ['transformers'] example_code: from transformers import BartTokenizer, BartModel\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\nmodel = BartModel.from_pretrained('facebook/bart-large')\ninputs = tokenizer(Hello, my dog is cute, return_tensors=pt)\noutputs = model(**inputs)\nlast_hidden_states = outputs.last_hidden_state performance: dataset: IMDb reviews accuracy: Not provided description: BART-Large is a larger version of the BART model, powerful for various NLP tasks including sentiment analysis and text classification."
